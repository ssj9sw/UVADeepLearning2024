{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc341ydr2CLE",
        "outputId": "afc2f66d-d886-4d6c-b6e4-8346ccdeaaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (0.36.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.36.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.36.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3grTnYl16PL",
        "outputId": "0cfe5c6d-69a6-465a-c9d5-0ebc442308ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/DL')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wcl10RMZ2HfH",
        "outputId": "0c463148-94db-448c-c064-a9141e818746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "3hixgSAa30gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "  def __init__(self, annotation_file, audio_dir, transformation = None):\n",
        "    self.annotations = pd.read_csv(annotation_file)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.transformation = transformation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    audio_sample_path = self._get_audio_sample_path(index)\n",
        "    label = self._get_audio_sample_label(index)\n",
        "    signal, sr = torchaudio.load(audio_sample_path)\n",
        "    signal = self._resample_if_necessary(signal, sr)\n",
        "    signal = self._mix_down_if_necessary(signal)\n",
        "\n",
        "    signal = self._cut_if_necessary(signal)\n",
        "    signal = self._right_pad_if_necessary(signal)\n",
        "    signal = self.transformation(signal)\n",
        "    return signal, label\n",
        "\n",
        "  def _resample_if_necessary(self, signal, sr):\n",
        "    if sr != 16000:\n",
        "      resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "      signal = resampler(signal)\n",
        "    return signal\n",
        "\n",
        "  def _mix_down_if_necessary(self, signal):\n",
        "    if signal.shape[0] > 1:\n",
        "      signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "    return signal\n",
        "\n",
        "  def _cut_if_necessary(self, signal):\n",
        "    if signal.ndim < 2:\n",
        "        raise ValueError(\"Expected signal to have at least two dimensions [C, T], got: {}\".format(signal.ndim))\n",
        "    if signal.shape[1] > 48000:\n",
        "      signal = signal[:, :48000]\n",
        "    return signal\n",
        "\n",
        "  def _right_pad_if_necessary(self, signal):\n",
        "    length_signal = signal.shape[1]\n",
        "    if length_signal < 48000:\n",
        "      num_missing_samples = 48000 - length_signal\n",
        "      last_dim_padding = (0, num_missing_samples)\n",
        "      signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "    return signal\n",
        "\n",
        "  def _get_audio_sample_path(self, index):\n",
        "    folder = self.annotations.iloc[index, 2]\n",
        "    path = os.path.join(self.audio_dir, folder, self.annotations.iloc[index,1])\n",
        "    return path\n",
        "\n",
        "  def _get_audio_sample_label(self, index):\n",
        "    return self.annotations.iloc[index, 3]"
      ],
      "metadata": {
        "id": "TgelTU9A-SAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=1024, hop_length=512, n_mels=64)"
      ],
      "metadata": {
        "id": "OfJIojDgWV9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capuchin_annotations = '/content/drive/MyDrive/DL/Parsed_Capuchinbird_Clips.csv'\n",
        "not_capuchin_annotations = '/content/drive/MyDrive/DL/Parsed_Not_Capuchinbird_Clips.csv'\n",
        "capuchin_dir = '/content/drive/MyDrive/DL/data'\n",
        "capuchin = AudioDataset(capuchin_annotations, capuchin_dir, mel_spectrogram)\n",
        "not_capuchin = AudioDataset(not_capuchin_annotations, capuchin_dir, mel_spectrogram)"
      ],
      "metadata": {
        "id": "Ss5GFoZ9BSmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(not_capuchin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAGXLYejCAWk",
        "outputId": "db614616-29d9-494d-b7e6-70ff0b1ef986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "593"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "data = ConcatDataset([capuchin, not_capuchin])"
      ],
      "metadata": {
        "id": "yplQYTykDLrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(data))\n",
        "val_size = len(data) - train_size\n",
        "train_data, val_data = random_split(data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "QaQ4nyX8LwNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "FwpoNknsOFcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the fully connected layer to match the number of classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "# Move model to GPU if available\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "#criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "DqHBQC0aaEUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lxRR5gvIlRfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  losses = []\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    temp = []\n",
        "    # Compute prediction and loss\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    temp.append(loss.item())\n",
        "\n",
        "    if batch % 20 == 0:\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        losses.append(loss)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  return losses\n",
        "\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss, correct"
      ],
      "metadata": {
        "id": "KmY50nJ7lhse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "accuracy = []\n",
        "\n",
        "epochs = 10\n",
        "training_losses = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    model.train()\n",
        "    loss_tr = train_loop(train_loader, model, criterion, optimizer)\n",
        "    train_loss_avg = sum(loss_tr) / len(loss_tr)\n",
        "    train_loss.append(train_loss_avg)\n",
        "    #train_loop(train_dl, model, criterion, optimizer)\n",
        "    model.eval()\n",
        "    loss_vl, acc = test_loop(val_loader, model, criterion)\n",
        "    val_loss.append(loss_vl)\n",
        "    accuracy.append(acc)\n",
        "\n",
        "print('Training done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0dgeRa8lpbv",
        "outputId": "d6f7c31f-1eea-4a7e-ae04-7cbf26050137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.647581  [   16/  648]\n",
            "loss: 0.484001  [  336/  648]\n",
            "loss: 0.657976  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.199659 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.322062  [   16/  648]\n",
            "loss: 0.090585  [  336/  648]\n",
            "loss: 0.385419  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.069068 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.198038  [   16/  648]\n",
            "loss: 0.187826  [  336/  648]\n",
            "loss: 0.347235  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.158197 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.543897  [   16/  648]\n",
            "loss: 0.022252  [  336/  648]\n",
            "loss: 0.159932  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.083216 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.265703  [   16/  648]\n",
            "loss: 0.043587  [  336/  648]\n",
            "loss: 0.027689  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.114665 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.018388  [   16/  648]\n",
            "loss: 0.073593  [  336/  648]\n",
            "loss: 0.021994  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.153872 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.118564  [   16/  648]\n",
            "loss: 0.006986  [  336/  648]\n",
            "loss: 0.028911  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.140304 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.109466  [   16/  648]\n",
            "loss: 0.020881  [  336/  648]\n",
            "loss: 0.049675  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.058405 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.004655  [   16/  648]\n",
            "loss: 0.027059  [  336/  648]\n",
            "loss: 0.007481  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.023318 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.009213  [   16/  648]\n",
            "loss: 0.286289  [  336/  648]\n",
            "loss: 0.010919  [  328/  648]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.023518 \n",
            "\n",
            "Training done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "optimizer_state = optimizer.state_dict()  # Assuming 'optimizer' is your optimizer\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer_state,\n",
        "}, 'model_checkpoint.pth')\n",
        "'''"
      ],
      "metadata": {
        "id": "Y8Lmar_TnxS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Re-create the model architecture\n",
        "model = TheModelClass(*args, **kwargs)  # Replace with your model class and parameters\n",
        "\n",
        "# Load the state dictionary\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "\n",
        "# If you saved the complete checkpoint including optimizer state:\n",
        "checkpoint = torch.load('model_checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# If you also need to load the optimizer state:\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "'''\n"
      ],
      "metadata": {
        "id": "M9GORa_mpvo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = next(iter(val_loader))"
      ],
      "metadata": {
        "id": "qNi3kPgJp1cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_numpy = X_test.numpy()\n",
        "y_test_numpy = y_test.numpy()"
      ],
      "metadata": {
        "id": "pkTHsvglqUvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_2 = torch.tensor(X_test).float().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFeoixrkrDkD",
        "outputId": "95033fa3-c206-461f-e95b-38b5c93e8a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-ad07b0771321>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test_2 = torch.tensor(X_test).float().to(device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    yhat = model(X_test_2)\n",
        "yhat_prob = torch.softmax(yhat, dim=1)\n",
        "_, predicted_classes = torch.max(yhat_prob, 1)"
      ],
      "metadata": {
        "id": "iWFcSPm2qYjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(yhat_prob[:, 1] >= 0.5).long()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAalqreOr15r",
        "outputId": "c491c453-5845-4a65-a69e-96c48d1e4d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1_XD7OFsEP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OTWYW6UCujlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0Ad8fGYujn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def load_mp3_16k_mono(filename):\n",
        "    waveform, sample_rate = torchaudio.load(filename)\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    if sample_rate != 16000:\n",
        "        transformer = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        waveform = transformer(waveform)\n",
        "    return waveform.squeeze()\n",
        "\n",
        "def preprocess_audio(audio_tensor):\n",
        "    zero_padding = torch.zeros(48000 - audio_tensor.shape[0])\n",
        "    audio_tensor = torch.cat((zero_padding, audio_tensor), dim=0)\n",
        "    spectrogram = torchaudio.transforms.Spectrogram(n_fft=320, hop_length=32)(audio_tensor)\n",
        "    return torch.abs(spectrogram).unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "Z_sseX8Qujy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4sYxK6XusqY",
        "outputId": "5dd1ed66-0509-4c59-de18-508a05550626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "directory = '/content/drive/MyDrive/DL/data/Forest Recordings'\n",
        "model.to('cpu')\n",
        "\n",
        "for file in os.listdir(directory):\n",
        "    FILEPATH = os.path.join(directory, file)\n",
        "    waveform = load_mp3_16k_mono(FILEPATH)\n",
        "\n",
        "    # Split waveform into chunks of 48000 samples\n",
        "    chunks = waveform.unfold(0, 48000, 48000)  # Non-overlapping chunks\n",
        "\n",
        "    # Preprocess and collect all chunks\n",
        "    preprocessed_chunks = [preprocess_audio(chunk) for chunk in chunks]\n",
        "\n",
        "    # Create a dataset and a DataLoader for batching\n",
        "    dataset = TensorDataset(torch.stack(preprocessed_chunks))\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Predict\n",
        "    predictions = []\n",
        "    for batch in dataloader:\n",
        "        inputs = batch[0]  # Already on CPU by default\n",
        "        outputs = model(inputs)  # Model and inputs both on CPU\n",
        "        predictions.extend(outputs.detach().numpy())  # No need to call .cpu() on detach\n",
        "\n",
        "    results[file] = predictions"
      ],
      "metadata": {
        "id": "_Oul3Tn5unzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "1SrpvOOfwVNp",
        "outputId": "1c612199-421e-4ee8-87ca-03d063217a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-14e46ab0c097>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "    class_preds[file] = [1 if any(pred > 0.99 for pred in prediction) else 0 for prediction in logits]"
      ],
      "metadata": {
        "id": "3iJ4-jBm2ltB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds['recording_98.mp3']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIgInDi52rpu",
        "outputId": "2a9747d7-4197-4317-87b5-51abbbd0d522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['recording_00.mp3']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcnnGlnJ3hJL",
        "outputId": "dfd07be7-d0d3-48f4-a566-ded2fb61b69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 1.7783755, -1.743832 ], dtype=float32),\n",
              " array([ 1.7598797, -1.7275972], dtype=float32),\n",
              " array([ 1.8523972, -1.8177593], dtype=float32),\n",
              " array([ 1.9886256, -1.9529644], dtype=float32),\n",
              " array([ 0.5798351 , -0.61253184], dtype=float32),\n",
              " array([ 1.8498255, -1.8148897], dtype=float32),\n",
              " array([ 1.7847242, -1.7497902], dtype=float32),\n",
              " array([ 1.7890346, -1.7542467], dtype=float32),\n",
              " array([ 1.8223507, -1.7877554], dtype=float32),\n",
              " array([ 1.7973251, -1.7624512], dtype=float32),\n",
              " array([ 1.7852842, -1.7506639], dtype=float32),\n",
              " array([ 1.7709395, -1.7363927], dtype=float32),\n",
              " array([ 1.7723894, -1.7383232], dtype=float32),\n",
              " array([ 1.9540703, -1.9167547], dtype=float32),\n",
              " array([ 0.59402263, -0.6289    ], dtype=float32),\n",
              " array([ 1.7831537, -1.7482643], dtype=float32),\n",
              " array([ 1.7178625, -1.6915476], dtype=float32),\n",
              " array([ 1.7877142, -1.7526518], dtype=float32),\n",
              " array([ 1.7766523, -1.7415922], dtype=float32),\n",
              " array([ 1.7446396, -1.7094357], dtype=float32),\n",
              " array([ 1.7874607, -1.7525547], dtype=float32),\n",
              " array([ 1.7627995, -1.728    ], dtype=float32),\n",
              " array([ 1.7264374, -1.6907924], dtype=float32),\n",
              " array([ 1.3212454, -1.2929957], dtype=float32),\n",
              " array([ 0.62671614, -0.65858835], dtype=float32),\n",
              " array([ 1.8219677, -1.788117 ], dtype=float32),\n",
              " array([ 1.8250743, -1.7907014], dtype=float32),\n",
              " array([ 1.7898636, -1.7549514], dtype=float32),\n",
              " array([ 1.8432336, -1.8089125], dtype=float32),\n",
              " array([ 1.7850128, -1.7502115], dtype=float32),\n",
              " array([ 1.7749342, -1.7399014], dtype=float32),\n",
              " array([ 1.7742592, -1.7393574], dtype=float32),\n",
              " array([ 2.4387488, -2.3450124], dtype=float32),\n",
              " array([ 1.9164493, -1.8744693], dtype=float32),\n",
              " array([ 1.7868438, -1.7521627], dtype=float32),\n",
              " array([ 1.7745283, -1.7414403], dtype=float32),\n",
              " array([ 0.8854049 , -0.90629816], dtype=float32),\n",
              " array([ 1.6589777, -1.6325595], dtype=float32),\n",
              " array([ 1.7611681, -1.7261378], dtype=float32),\n",
              " array([ 1.7162843, -1.6810284], dtype=float32),\n",
              " array([ 1.7644677, -1.7295096], dtype=float32),\n",
              " array([ 1.7755163, -1.740718 ], dtype=float32),\n",
              " array([ 1.7636304, -1.7285594], dtype=float32),\n",
              " array([ 1.7080681, -1.6729584], dtype=float32),\n",
              " array([ 1.7159628, -1.6805995], dtype=float32),\n",
              " array([ 1.6468047, -1.6118672], dtype=float32),\n",
              " array([ 0.5350092 , -0.57315516], dtype=float32),\n",
              " array([ 1.0751576, -1.0487387], dtype=float32),\n",
              " array([ 1.5283337, -1.4924188], dtype=float32),\n",
              " array([ 1.7027582, -1.6674333], dtype=float32),\n",
              " array([ 1.6217141, -1.5931647], dtype=float32),\n",
              " array([ 1.7262349, -1.6922115], dtype=float32),\n",
              " array([ 1.7721491, -1.7370512], dtype=float32),\n",
              " array([ 1.8021878, -1.7685506], dtype=float32),\n",
              " array([ 1.7661881, -1.7311093], dtype=float32),\n",
              " array([ 1.8382919, -1.8025721], dtype=float32),\n",
              " array([ 1.7705882, -1.7346675], dtype=float32),\n",
              " array([ 1.3516757, -1.3193492], dtype=float32),\n",
              " array([ 1.5136688, -1.4794102], dtype=float32),\n",
              " array([ 1.7851759, -1.7501887], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "postprocessed = {}\n",
        "for file, scores in class_preds.items():\n",
        "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
        "postprocessed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19vhyJW-30Xo",
        "outputId": "37ec6c0f-88ca-4404-ea96-7edb91642d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'recording_00.mp3': 6,\n",
              " 'recording_01.mp3': 4,\n",
              " 'recording_02.mp3': 1,\n",
              " 'recording_03.mp3': 1,\n",
              " 'recording_04.mp3': 4,\n",
              " 'recording_05.mp3': 1,\n",
              " 'recording_06.mp3': 4,\n",
              " 'recording_07.mp3': 3,\n",
              " 'recording_08.mp3': 18,\n",
              " 'recording_09.mp3': 1,\n",
              " 'recording_10.mp3': 5,\n",
              " 'recording_11.mp3': 3,\n",
              " 'recording_12.mp3': 1,\n",
              " 'recording_14.mp3': 1,\n",
              " 'recording_13.mp3': 1,\n",
              " 'recording_15.mp3': 3,\n",
              " 'recording_16.mp3': 2,\n",
              " 'recording_17.mp3': 4,\n",
              " 'recording_18.mp3': 11,\n",
              " 'recording_19.mp3': 1,\n",
              " 'recording_20.mp3': 1,\n",
              " 'recording_21.mp3': 2,\n",
              " 'recording_22.mp3': 3,\n",
              " 'recording_23.mp3': 3,\n",
              " 'recording_24.mp3': 1,\n",
              " 'recording_27.mp3': 1,\n",
              " 'recording_26.mp3': 2,\n",
              " 'recording_25.mp3': 3,\n",
              " 'recording_29.mp3': 2,\n",
              " 'recording_28.mp3': 3,\n",
              " 'recording_30.mp3': 4,\n",
              " 'recording_31.mp3': 1,\n",
              " 'recording_32.mp3': 3,\n",
              " 'recording_33.mp3': 1,\n",
              " 'recording_34.mp3': 4,\n",
              " 'recording_35.mp3': 1,\n",
              " 'recording_37.mp3': 4,\n",
              " 'recording_38.mp3': 2,\n",
              " 'recording_36.mp3': 12,\n",
              " 'recording_41.mp3': 1,\n",
              " 'recording_40.mp3': 2,\n",
              " 'recording_42.mp3': 4,\n",
              " 'recording_39.mp3': 5,\n",
              " 'recording_43.mp3': 6,\n",
              " 'recording_44.mp3': 2,\n",
              " 'recording_46.mp3': 4,\n",
              " 'recording_45.mp3': 4,\n",
              " 'recording_47.mp3': 5,\n",
              " 'recording_48.mp3': 5,\n",
              " 'recording_51.mp3': 4,\n",
              " 'recording_49.mp3': 1,\n",
              " 'recording_50.mp3': 1,\n",
              " 'recording_52.mp3': 6,\n",
              " 'recording_53.mp3': 1,\n",
              " 'recording_56.mp3': 4,\n",
              " 'recording_55.mp3': 1,\n",
              " 'recording_54.mp3': 3,\n",
              " 'recording_57.mp3': 3,\n",
              " 'recording_58.mp3': 1,\n",
              " 'recording_59.mp3': 5,\n",
              " 'recording_60.mp3': 6,\n",
              " 'recording_62.mp3': 13,\n",
              " 'recording_61.mp3': 4,\n",
              " 'recording_64.mp3': 3,\n",
              " 'recording_63.mp3': 5,\n",
              " 'recording_65.mp3': 4,\n",
              " 'recording_66.mp3': 1,\n",
              " 'recording_67.mp3': 3,\n",
              " 'recording_68.mp3': 1,\n",
              " 'recording_70.mp3': 3,\n",
              " 'recording_71.mp3': 6,\n",
              " 'recording_69.mp3': 2,\n",
              " 'recording_73.mp3': 1,\n",
              " 'recording_72.mp3': 5,\n",
              " 'recording_74.mp3': 8,\n",
              " 'recording_76.mp3': 1,\n",
              " 'recording_75.mp3': 2,\n",
              " 'recording_77.mp3': 4,\n",
              " 'recording_78.mp3': 5,\n",
              " 'recording_80.mp3': 2,\n",
              " 'recording_79.mp3': 1,\n",
              " 'recording_81.mp3': 5,\n",
              " 'recording_83.mp3': 1,\n",
              " 'recording_82.mp3': 5,\n",
              " 'recording_84.mp3': 4,\n",
              " 'recording_85.mp3': 2,\n",
              " 'recording_86.mp3': 6,\n",
              " 'recording_87.mp3': 17,\n",
              " 'recording_88.mp3': 5,\n",
              " 'recording_89.mp3': 3,\n",
              " 'recording_90.mp3': 1,\n",
              " 'recording_91.mp3': 1,\n",
              " 'recording_92.mp3': 1,\n",
              " 'recording_93.mp3': 6,\n",
              " 'recording_94.mp3': 3,\n",
              " 'recording_95.mp3': 6,\n",
              " 'recording_96.mp3': 1,\n",
              " 'recording_97.mp3': 3,\n",
              " 'recording_98.mp3': 20,\n",
              " 'recording_99.mp3': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hxat5VpE4iyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}